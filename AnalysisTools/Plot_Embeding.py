"""
=============================================================================
Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...
=============================================================================

An illustration of various embeddings on the digits dataset.

The RandomTreesEmbedding, from the :mod:`sklearn.ensemble` module, is not
technically a manifold embedding method, as it learn a high-dimensional
representation on which we apply a dimensionality reduction method.
However, it is often useful to cast a dataset into a representation in
which the classes are linearly-separable.

t-SNE will be initialized with the embedding that is generated by PCA in
this example, which is not the default setting. It ensures global stability
of the embedding, i.e., the embedding does not depend on random
initialization.
"""

# Authors: Fabian Pedregosa <fabian.pedregosa@inria.fr>
#          Olivier Grisel <olivier.grisel@ensta.org>
#          Mathieu Blondel <mathieu@mblondel.org>
#          Gael Varoquaux
# License: BSD 3 clause (C) INRIA 2011

print(__doc__)
from time import time

import os
import h5py
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import offsetbox
from sklearn import (manifold, datasets, decomposition, ensemble,
                     discriminant_analysis, random_projection)

def PlotTwoImage(X, Annotation, Prediction):
   plt.figure(figsize=(36, 36))

   plt.figure(1)
   ax1 = plt.subplot(211)
   for i in range(len(X)):
       Anno = np.nonzero(Annotation[i])[0][0]
       #Anno = result_anno[i]
       plt.text(X[i, 0], X[i, 1], repr(Anno),
                color=plt.cm.Set1(Anno / 17.),
                fontdict={'weight': 'bold', 'size': 9})


   ax2 = plt.subplot(212)
   for i in range(len(X)):
       Anno = Prediction[i]
       #Anno = result_anno[i]
       plt.text(X[i, 0], X[i, 1], str(Anno),
                color=plt.cm.Set1(Anno / 17.),
                fontdict={'weight': 'bold', 'size': 9})
   ax1.set_title('Annotation')
   ax2.set_title('Prediction')
   plt.show()


def PlotOneImage(X,y):
   plt.figure(figsize=(40, 40))

   ax = plt.subplot(111)

   for i in range(len(X)):
       Anno = y[i]
       #Anno = result_anno[i]
       plt.text(X[i, 0], X[i, 1], str(Anno),
                color=plt.cm.Set1(Anno / 17.),
                fontdict={'weight': 'bold', 'size': 9})
   plt.show()
def PrecessData(ProjectionMethod):
    fid = h5py.File('data/validation.h5')

    X = np.load('validation_soft_labels.npy')[ 0: 10000,:]

    result_anno = fid['label'][0: 10000]
    print(np.nonzero(result_anno[0])[0][0])
    result_pred = np.load('validation_results_anno.npy')[0: 10000]
    print(result_pred[0])
    n_samples, n_features = X.shape
    n_neighbors = 30

    # Projection on to the first 2 principal components
    print("Computing PCA projection")
    if ProjectionMethod == 'TSNE' :
        clf = manifold.TSNE(n_components=2, init='pca', random_state=0)
    elif ProjectionMethod == 'MDS' :
        clf = manifold.MDS(n_components=2, n_init=1, max_iter=100)
    elif ProjectionMethod == 'LLE' :
        clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2, method='standard')

    X_decom = clf.fit_transform(X) #decomposition.TruncatedSVD(n_components=2).fit_transform(X)
    print(X_decom.shape)

    x_min, x_max = np.min(X_decom, 0), np.max(X_decom, 0)
    X = (X_decom - x_min) / (x_max - x_min)
    PlotTwoImage(X, result_anno, result_pred)
if __name__ == '__main__':
    ProjectionMethod = 'TSNE'
    PrecessData(ProjectionMethod)

#plt.savefig(os.path.join(model_dir, '845_first8000.jpg'))model_dir = 'results'
'''
# t-SNE embedding of the digits dataset
print("Computing t-SNE embedding")
tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)
t0 = time()
X_tsne = tsne.fit_transform(X)

plot_embedding(X_tsne,
               "t-SNE embedding of the digits (time %.2fs)" %
               (time() - t0))

plt.show()
'''
